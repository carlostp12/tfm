---
title: "PAC2_Estadística_CARLOS_TORO_PEÑAS"
author: "Carlos Toro Peñas"
date: '2022-11-08'
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  word_document: default
  pdf_document:
    toc: yes
    number_sections: true
    df_print: kable
    highlight: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}

if (!require('jsonlite')) install.packages('jsonlite')
library(jsonlite)
if (!require('dbscan')) install.packages('dbscan')
library(dbscan)
if (!require('readr')) install.packages('readr')
library(readr)
if (!require('rjson')) install.packages('rjson')
library(rjson)

if (!require('dplyr')) install.packages('dplyr')
library(dplyr)

if (!require('akima')) install.packages('akima')
library(akima)

if (!require('astrolibR')) install.packages("astrolibR")
library(astrolibR)

if (!require('scatterplot3d')) install.packages("scatterplot3d")
library(scatterplot3d)

if (!require('gMOIP')) install.packages("gMOIP")
library(gMOIP)

if (!require('ggplot2')) install.packages("ggplot2")
library(ggplot2)

if (!require('rgl')) install.packages("rgl")
library(rgl)

if (!require('pracma')) install.packages("pracma")
library(pracma)

if (!require('plotly')) install.packages("plotly")

library(plotly)

if (!require('sqldf')) install.packages("sqldf")
library(sqldf)

if (!require('tidyr')) install.packages("tidyr")
library(tidyr)

if (!require('densityClust')) install.packages('densityClust')
library(densityClust)
```

# Loading data files

## Galaxy catalog for 2dFGRS

```{r echo=FALSE, message=FALSE, warning=FALSE}
######################
#     Galaxy 2dFGRS loading # 
######################

setwd('C:/Users/Carlos/OneDrive/data-science/TFM/tfm/data')
dt <- read.csv('../data/2dfgrs-title-dist.csv')
str(dt)
```

## Galaxy group catalog for 2dFGRS

```{r echo=FALSE, message=FALSE, warning=FALSE}
######################
#     GROUPS loading #    
###################### 
setwd('C:/Users/Carlos/OneDrive/data-science/TFM/tfm/data')
dt_groups <- read.csv('../data/groups/group_members.csv', sep = ',')       


```

Fileds for out clustering analisys are: ID, x, y, z, redshift, distance.

# Data Preprocessing

## Descriptive analysis. **Data selection and visualization**

There is an initial preprocessing of data-file in order to obtain proper distances and cartesian coordinates x,y,z, by now it is omitted here.

Take a sample with: minPts = 5, minQ_Z\>3 and by RA and DEC:

$$RA \in [0, 1],\, DEC \in [-29, -27],\, \,and\,\, z \lt max\_redshift$$

```{r}
min_members <- 5
max_redshift <- 0.3
ra_lim_inf <-  0
ra_lim_sup <- 1
dec_lim_inf <- -29
dec_lim_sup <-  -27

# Take a sample using boundaries
dt_sample3 <- dt[dt$Q_Z>3 & dt$RAh<= ra_lim_sup & 
              dt$RAh>=ra_lim_inf & dt$Ded>= dec_lim_inf & 
              dt$Ded<=dec_lim_sup & dt$Z< max_redshift,]

#Change column name
names(dt_sample3)[names(dt_sample3) == 'Z'] <- 'redshift'

#Take the parameters necessary for clustering effect.
dt_sample3<- dt_sample3[,c('SEQNUM','x', 'y', 'z', 'redshift',  "dist")]

# mm is an object containing both groups and galaxy identification
mm<-merge(dt_sample3, dt_groups, by.x = 'SEQNUM', by.y = 'ID_2DF')
ggplot(dt_sample3, aes(x=redshift, y=redshift))+geom_violin()
```

Select groups with more than min_members members

```{r}
h<-sqldf("select 
            count(SEQNUM) as members, 
            GROUP_ID 
          from mm 
          group by GROUP_ID 
          order by  members desc")  
mm5<-sqldf(sprintf("
    SELECT 
        mm.SEQNUM,
        mm.x, 
        mm.y, 
        mm.z, 
        mm.GROUP_ID, 
        mm.redshift, 
        mm.dist, 
        mm.GAL_ID 
      FROM 
        mm as mm, h 
      where 
          mm.GROUP_ID=h.GROUP_ID and 
          h.members >= %s"
      , min_members))

update_mm5 <- function(mm){
	mm5<-sqldf(sprintf("
	      select
	          mm.SEQNUM,
	          mm.x, 
	          mm.y, 
	          mm.z, 
	          mm.GROUP_ID, 
	          mm.redshift, 
	          mm.dist, 
	          mm.GAL_ID, 
	          mm.cluster_id 
	      from 
	          mm as mm, h 
        where 
            mm.GROUP_ID=h.GROUP_ID and 
	          h.members >= %s", min_members))
	mm5
}
true_groups <- length(unique(mm5$GROUP_ID))

print(
  sprintf('Number of galaxies in groups with more than %s elements %s out of %s', 
          min_members, 
          dim(mm5)[1], 
          dim(mm)[1]))
print(sprintf("Number of groups with more than %s members: %s", 
              min_members, 
              true_groups))
```

We take a look at the groups with more than min_members:

```{r}
hhh<- h[h$members>=min_members, ]
ttable <- table(hhh$GROUP_ID, hhh$members)
barplot(ttable, col=('red'), 
        main=sprintf("Group distribution (%s) with at least %s members ", 
                     true_groups, 
                     min_members))
```

```{r}

boxplot(hhh$members, main="Boxplot of wt")
```

# Raw data processing

Optics clustering:

```{r}
points<- mm[,c('x', 'y', 'z')]

#clustering
res <- optics(points, minPts = min_members)
plot(res)

```

DBSCAN application:

```{r}
blo_scan <- extractDBSCAN(res, eps_cl = 0.00075)
mm$cluster_id <- blo_scan$cluster
mm5 <- update_mm5(mm)
plot(blo_scan)
```

## Out-put clusters visualization

We have, on one hand all groups with more than min_members members (made up by a reduced amount of galaxies from catalog):

```{r}
plot3d(mm5$x, mm5$y, mm5$z, col = mm5$GROUP_ID, 
       size = 2, xlab = "X", ylab = "Y", zlab = "Z")
```

in the other hand the output-clusters from DBSCAN:

```{r}
plot3d(points$x, points$y, points$z, 
       col = blo_scan$cluster + 1, size = 2, 
       xlab = "X", ylab = "Y", zlab = "Z")
```

## Functions to asses outcomes

To aseess the outcomes we will based our analysis on two basic concepts:

**Purity(P)**: measure of an output-cluster: proportion of members are exclusively from a single true group, providing confidence that the algorithm correctly groups members together. A high purity rate indicates the algorithm's effectiveness in identifying true groupings.

**Completeness (C)**: measure of original cluster: proportion of data true-group included in an output-cluster. A original group is considered "complete" if all data points are assigned to the same cluster.

Therefore Purity is a measure of output-clusters and Completeness is a measure in original groups.

For this study we consider an output-cluster to be pure if P\>=0.66 (at least 2/3 of elements of an output-cluster belong to a single group). An original cluster is complete if C\>=0.5 (at least half data belong to an original true group)

**total_in_group:** number of elements in a given group.

**total_in_cluster:** number of elements in a given output-cluster.

**total_in_cluster_group:** number of elements in a given output-cluster belonging to a majority-group.

**undetected_groups**: original groups not detected as majority-group in output-clusters

length(unique(all\$cluster_id)),

length(unique(all\$group_id)),

Following code is devoted to asses the outcomes obtained with from an given output-cluster:

```{r}

###############################################################################
#	Number of elements in a given output-cluster
###############################################################################
calculate_count_of_cluster <- function(cluster_id, dataset){
	ttotal<-sqldf(sprintf("
	    select 
	      count(SEQNUM) as how_many
			from 
			  dataset
			where 
	       cluster_id =%s", cluster_id))
}


###############################################################################
#	Number of elements in a given true-group
###############################################################################
calculate_count_of_group <- function(group_id, dataset){
	ttotal<-sqldf(sprintf("
	  select 
	    count(SEQNUM) as how_many
		from 
		  dataset
		where 
		  group_id=%s
		group by 
	    group_id", group_id)) 
    list('how_many' = ttotal$how_many)
}


###############################################################################
#	The most common group of a given cluster and count elements in the
#	intersection group and cluster.
###############################################################################
calculate_majority_group <- function(cluster_id, dataset){
	ttotal<-sqldf(sprintf("
	  select 
	    count(SEQNUM) as how_many,
			group_id as group_id
		from 
		  dataset
		where 
		  cluster_id=%s
		  
		group by 
			group_id
		order by 
		  how_many desc 
	    limit 1", cluster_id)) 
    list('group_id' = ttotal$group_id,
         'how_many' = ttotal$how_many)
}

###############################################################################
#	The same restricted to number of members> min_members 
###############################################################################
calculate_real_majority_group <- function(cluster_id, dataset){
	ttotal<-sqldf(sprintf("
	select 
	    count(SEQNUM) as how_many,
			group_id as group_id
	from mm
			where cluster_id=%s
	group by 
	    group_id
	order by 
	    how_many desc
			limit 1", cluster_id)) 
    list('group_id' = ttotal$group_id, 'how_many' = ttotal$how_many)
}

###############################################################################
#	Purity and Completeness: 
#		1- how many per cluster are present in a group.
#		2- how many in the majority group.
#	A cluster is said to be pure if 2-/1- >= 0.666 
#	A cluster is said to be complete if 1-/2- >= 0.5 
###############################################################################
calculate_stats <- function(cluster_id, dataset) {
  #print(sprintf('Calculating stats for  clusterID %s', cluster_id))
  total<-calculate_majority_group(cluster_id, dataset)
  #Number of elements in the cluster_id that also belong
  #to majority group
  total_in_cluster_group <- total$how_many
  group_id <- total$group_id
  
  #Total number of elements in a group
  total_in_group <- calculate_count_of_group(group_id, dataset)
  total_in_group <- total_in_group$how_many
  
  #Total number of elements in a cluster
  total_in_cluster<-calculate_count_of_cluster(cluster_id, dataset)
  total_in_cluster <- total_in_cluster$how_many
  
  #Purity: all of group in cluster/total un cluster
  purity <- ifelse(total_in_cluster > 0, total_in_cluster_group/total_in_cluster, 0)
  #completeness: all of group in cluster/total un group
  completeness <- ifelse(total_in_group > 0, total_in_cluster_group/total_in_group, 0)	
  
  bad_classified <- total_in_group - total_in_cluster_group # belowing to group but classified outside
  spurious <- total_in_cluster - total_in_cluster_group # Outside of the group classified inside
  list('cluster_id' = cluster_id, 
		'group_id' = group_id , 
		'total_in_group' = total_in_group, 
		'total_in_cluster' = total_in_cluster, 
		'total_in_cluster_group' = total_in_cluster_group,
		'purity' = purity,
		'completeness' = completeness,
		'spurious' = spurious,
		'bad_classified' = bad_classified,
		'is_pure' = ifelse(purity>=0.666, 1, 0),
		'is_complete' = ifelse(completeness >= 0.5, 1, 0)
	   )
}


############################################################################
# Execute stats from a given mm dataset and a db_scan execution result
# delete column from dataframe: mm <- select(mm, -'cluster')
############################################################################
execute_stats <- function(mm, blo_scan){
  
	#mm0 <- mm[mm$cluster != 0, ]
	cluster_results <-sqldf("
    select 
	    distinct(cluster_id) AS cluster
		FROM 
	    mm")
	stats <- data.frame('cluster_id'=integer(),
		'group_id'=integer(),
		'total_in_group'=integer(),
		'total_in_cluster'=integer(),
		'total_in_cluster_group'=integer(),
		'purity'=numeric(),
		'completn'=numeric(),
		'spurious'=numeric(),
		'bad_class'=numeric(),
		'is_pur'=integer(),
		'is_comp'=integer()		
		)
	for(r in cluster_results$cluster){
	  if(r != 0) {
		bb <- calculate_stats(r, mm)
		stats[nrow(stats) +1,] <- 
			c(  bb$cluster_id, 
				bb$group_id, 
				bb$total_in_group, 
				bb$total_in_cluster, 
				bb$total_in_cluster_group, 
				bb$purity, 
				bb$completeness, 
				bb$spurious,
				bb$bad_classified,
				bb$is_pure,  
				bb$is_complete)
		}
		#print(r)
	}
	return (stats)
}

undetected_groups <- function(dataset){
  groups_results <-sqldf("
    select 
        distinct(GROUP_ID)
    from 
        mm5
    where 
      group_id not in (
        select 
          distinct(group_id) as group_id
		    from
          dataset
        )")
   groups_results
}


# Pretty print a vector preceded by a title
pretty_print <- function (title, avector= c()){
  paste(title, do.call(paste, c(as.list(avector), sep = " ")))  
}
```

Now we apply to our DBSCAN:

```{r R.options=list(max.print=10)}
all <- execute_stats(mm, blo_scan)
head(all, 5)
```

We have

```{r}
print(paste("Mean purity", mean(all$purity)))
print(paste("Mean completness", mean(all$completn)))
s<- undetected_groups(all)
print(paste("Undetected groups", length(s$GROUP_ID), "out of", true_groups))
print(paste("Detected real groups", (true_groups-length(s$GROUP_ID)), "out of", true_groups))

```

We can create a function which test over different values of to test our DBSCAN:

```{r}
##
#Note that all$cluster_id (cluster_list), and all$group_id (group_list) are all
# refered to a complete original lluster an d
calculate_output <- function(test_eps_cl, res_data){
  blo_scan <- extractDBSCAN(res_data, eps_cl = test_eps_cl)
  mm$cluster_id <- blo_scan$cluster
  mm5 <- update_mm5(mm)
  predicted_groups <- length(unique(mm$cluster_id))
  all <- execute_stats(mm, blo_scan)
  number_pure_groups <- nrow(all[all$purity >= 0.666,])
  number_complete_groups <- nrow(all[all$completn>=0.5,])
  number_pure_complete_groups <- nrow(all[all$purity >= 0.666 & all$completn >= 0.5,])
  fp <- number_pure_groups/predicted_groups
  fr <- number_pure_complete_groups / true_groups
  s <- undetected_groups(all)
  c(mean(all$purity), 
    mean(all$completn), 
    length(unique(all$cluster_id)), 
    length(unique(all$group_id)), 
    number_pure_groups, 
    number_complete_groups, 
    number_pure_complete_groups, 
    fp, fr, 
    length(s$GROUP_ID), 
    mean(all$spurious), 
    mean(all$bad_class)
  )
}


extract_stats <- function (eps_sequence_values, local_res) {
	stats <- data.frame(
		'purity_list'=integer(),
		'completeness_list'=integer(),
		'cluster_list'=integer(),
		'group_list'=integer(),
		'pures'=integer(),
		'completes'=integer(),
		'pure_complet'=integer(),
		'fp_list'=numeric(),
		'fr_list'=numeric(),
		'und_gr'=numeric(),
		'spurious'=numeric(),
		'bad_class'=numeric()
		
		)
		
	for (eps_test in eps_sequence_values) {
		alli <- calculate_output(eps_test, local_res)
		stats[nrow(stats) +1,] <- 
			c(alli[1], alli[2], alli[3], 
			  alli[4], alli[5], alli[6], 
			  alli[7],  alli[8],alli[9], 
			  alli[10], alli[11], alli[12])
	}
	(stats)
}
```

We can now test over different values in order to obtain optimal eps_cl hyper-parameter:

```{r}
#It is easy to transform onto a function which admits a sequence and a res set.
eps_sequence_test <- seq(0.0004, 0.001, 0.0002)
x_stats <- extract_stats(eps_sequence_test, res)
```

Show the results obtained:

```{r}
print ('############### DATA FOR eps values ############################')
pretty_print(pretty_print("EPS", eps_sequence_test))
print ('############### DATA FOR ############################')

print ('')
print ('')

pretty_print(pretty_print("Completeness", x_stats$completeness_list))
pretty_print(pretty_print("Purity", x_stats$purity_list))
pretty_print(pretty_print("Groups", x_stats$group_list))
pretty_print(pretty_print("Clusters", x_stats$cluster_list))
pretty_print(paste("True Groups", true_groups))
pretty_print(pretty_print("Und. Groups", x_stats$und_gr))
pretty_print(pretty_print("Complete gr.:", x_stats$completes))
pretty_print(pretty_print("C + P gr.:", x_stats$pure_complet))
pretty_print(pretty_print("Pure gr.:", x_stats$pures))
pretty_print(pretty_print("Fr:", x_stats$fr_list))
pretty_print(pretty_print("Fp:", x_stats$fp_list))
pretty_print(pretty_print("Spurious:", x_stats$spurious))
pretty_print(pretty_print("Bad class:", x_stats$bad_class))
```

Lets get a plots for completeness and purity:

```{r}
plot_purity_completeness <- function(
    eps_sequence, 
    purity_l, 
    completeness_l, 
    pures_com, 
    titles, 
    title = "",
    x=0,
    labelx = 'X', labely = 'Y'
    ){
    test_data <- data.frame('d1' = eps_sequence)	
    g<- ggplot(test_data, aes(eps_sequence)) +
        geom_line(aes(y = purity_l, colour = titles[1])) + 
        geom_line(aes(y = completeness_l, colour = titles[2]))+  
        geom_line(aes(y = pures_com, colour = titles[3]))+
    ggtitle(title) +
      labs(x = labelx, y = labely)
    
    if (x>0){  
     g+ geom_vline(xintercept = x, linetype="dotted",)
    }else{
      g
    }
}

plot_purity_completeness_trend <- function(
    eps_sequence, 
    purity_l, 
    completeness_l, 
    titles, 
    title = "",
    x = 0,
    labelx = 'X', labely = 'Y')
  {
    test_data <- data.frame('d1' = eps_sequence)	
    g <- ggplot(test_data, aes(eps_sequence)) +
        geom_line(aes(y = purity_l, colour = titles[1])) + 
        geom_line(aes(y = completeness_l, colour = titles[2]))+
    ggtitle(title) +
    labs(x = labelx, y = labely)
    if (x>0){  
      g + geom_vline(xintercept = x, linetype="dotted",)
    }else{
      g
    }
}
```

```{r}
plot_purity_completeness_trend(
  eps_sequence_test, 
  x_stats$purity_list, 
  x_stats$completeness_list, 
  c('Purity', 'Completeness'),
  "Purity/completeness on not scaled data",
  0.00055, 'eps', 'Percentage'
)
```

This chart shows that optimal point is around $0.00055$. Is at this value where completeness is maximum and purity is still high.

```{r}

plot_purity_completeness(
  eps_sequence_test, 
  x_stats$pures/true_groups, 
  x_stats$und_gr/true_groups, 
  x_stats$pure_complet/true_groups,
  c('Purity', 'Undetected gr.', 'Pure + Complet.'),
  "Group global group purity and undetected stats on not scaled data",
  0.0006, 'eps', 'Percentage'
)
```

According with previous chart, the optimal value is $\epsilon = 6.10^{4}$. Given that at this value is reach the maximum purity, purity+completeness and the number of undetected groups remains at minimum.

```{r}
plot_purity_completeness(
  eps_sequence_test, 
  x_stats$und_gr,
  x_stats$group_list, 
  true_groups - x_stats$und_gr,
  c('Undetected', 'Groups', 'Detected'),
  "Total purity and completeness on scaled data",
   0.00055, 'eps', 'Groups number'
)
```

Once again the optimal point is at $\epsilon = 6.10^{4}$.

# Normalized data processing

We will perform a scale of data, according with improves a lot the results:

```{r}
points_scaled <- scale(points)
ress <- optics(points_scaled, minPts = min_members)
#optimal value obtained
blo_scans <- extractDBSCAN(ress, eps_cl = 0.025)
mm$cluster_id <- blo_scans$cluster
mm5 <- update_mm5(mm)
```

Again we can do the same for scaled data:

```{r}
eps_sequence_test <- seq(0.02, 0.035, 0.005)
x_stats <- extract_stats(eps_sequence_test, ress)
```

```{r}

print ('############### DATA FOR eps values ############################')
pretty_print(pretty_print("EPS", eps_sequence_test))
print ('############### DATA FOR ############################')

print ('')
print ('')
pretty_print(pretty_print("Completeness", x_stats$completeness_list))
pretty_print(pretty_print("Purity", x_stats$purity_list))
pretty_print(pretty_print("Groups", x_stats$group_list))
pretty_print(pretty_print("Clusters", x_stats$cluster_list))
pretty_print(pretty_print("EPS", eps_sequence_test))
pretty_print(paste("True Groups", true_groups))
pretty_print(pretty_print("Und. Groups", x_stats$und_gr))
pretty_print(pretty_print("Complete gr.:", x_stats$completes))
pretty_print(pretty_print("Pure gr.:", x_stats$pures))
pretty_print(pretty_print("C + P gr.:", x_stats$pure_complet))
pretty_print(pretty_print("Fr:", x_stats$fr_list))
pretty_print(pretty_print("Fp:", x_stats$fp_list))
pretty_print(pretty_print("Spurious:", x_stats$spurious))
pretty_print(pretty_print("Bad class:", x_stats$bad_class))

```

```{r}
eps_sequence_test <- seq(0.02, 0.035, 0.005)
plot_purity_completeness_trend(
  eps_sequence_test, 
  x_stats$purity_list,
  x_stats$completeness_list, 
  c('Purity', 'Completeness'),
  "Purity and completeness on scaled data",
  0.0237, 'eps', 'Percentage'
)
```

Results are quite better when all variables are scaled to a mean=0, sd=1. The optimal value of eps gives more than 76% for both purity and completeness.

The same plots before

```{r}

plot_purity_completeness(
  eps_sequence_test, 
  x_stats$pures/true_groups, 
  x_stats$und_gr/true_groups, 
  x_stats$pure_complet/true_groups, 
  c('Purity', 'Undetected groups', 'Pur.+Comp.'),
  "Group purity and undetected stats on not scaled data",
  0.0237, 'eps', 'Percentage'
  )
```

```{r}
plot_purity_completeness(
  eps_sequence_test, 
  x_stats$und_gr,
  x_stats$group_list, 
  true_groups - x_stats$und_gr,
  c('Undetected', 'Groups', 'Detected'),
  "Purity and completeness on scaled data",
   0.0237, 'eps', 'Groups number'
)
```

```{r}
eps_sequence_test <- seq(0.02, 0.035, 0.005)
plot_purity_completeness_trend(
  eps_sequence_test, 
  x_stats$und_gr,
  x_stats$group_list, 
  c('Undetected', 'Groups'),
  "Purity and completeness on scaled data",
  0.0237, 'eps', 'Groups number'
)
```

## Hyperparameter tunning

We have selected that minPts = min_members, which is a reasonable value for interpreting a group / clustering.

From the DBSCAN theory we can use the elbow on:

```{r}
kNNdistplot(x = points_scaled, k = min_members)
abline(h = 0.0235, lty = 3) 
```

How reader can see, the "elbow theory" does not apply here, the reason for this is that we are not trying to optimize the clusters given by the algorithm, instead we are trying to detect groups of galaxies.

In addition are data belonging to actual clusters with more than min_members members, this reduced the space to 774 galaxies out of more than 5000.

We can infer that optimal value is content within the interval (0.0023, 0.0033).

# s-Distances (SLos application)

Following coder allow to calculate the sdistance: It consists in make a elongation along the line of sight

```{r}
#######################################
# Calculate angle between two points
#######################################
#nulos <- 0
calculate_angle <- function(v1, v2) {
	dot_product <- sum(v1 * v2)
	mod_v1 <- sqrt(sum(v1^2))
	mod_v2 <- sqrt(sum(v2^2))
	acos_angle <- dot_product / (mod_v1 * mod_v2)
	bool <- abs(acos_angle)  >1 | is.na(acos_angle)
	if(bool == TRUE) {
		0
	}else{
		acos(acos_angle)
	}
	
}


#######################################
# Calculate traverse distance from proper distance
# simple Angle X Distance
#######################################
traverse_distance <- function(v1, v2, distance) {
	calculate_angle(v1, v2) * distance
}


#######################################
# Calculate scaled distance symmetric way
#######################################
d_LOS_scaled_symmetric <- function(v1, v2, redshift1, redshift2) {
	(d_LOS(v1, v2, redshift1) + d_LOS(v2, v1, redshift2)) / 2
}


#######################################
# Calculate scaled distance between two given vectors
# sfactor is global constant, f.e sfactor=0.2
# This formulae comes from Hai-Xia-Ma:2025:
# https://arxiv.org/abs/2405.09855
#######################################
d_LOS <- function(v1, v2, redshift) {
	if(redshift< 0.01){
		sfactor <- 0.6
	} else if(redshift< 0.04){
		sfactor <- 0.5
	} else if(redshift< 0.06){
		sfactor <- 0.4
	} else if(redshift< 0.08){
		sfactor <- 0.35
	}else if(redshift< 0.1){
		sfactor <- 0.3
	}else if(redshift< 0.12){
		sfactor <- 0.19
	}else if(redshift< 0.15){
		sfactor <- 0.08
	}else if(redshift< 0.2){
		sfactor <- 0.01
	}else {
		sfactor <- 0.2
	}
	
	sfactor * sum((v1-v2)*v1) / sqrt(sum(v1^2))
}


#######################################
# Calculate elongated distance
# depends on sfactor (a factor, for example sfactor=0.2) and proper_distance
# v1 = c(x, y, x, distance)
# sfactor must be a global variable
#######################################
s_distance <- function(v1, v2){
	vector1 <- v1[1:3]
	vector2 <- v2[1:3]
	proper_distance <- v1[4]
	redshift1 <- v1[5]
	redshift2 <- v2[5]
	
    sqrt (traverse_distance(vector1, vector2, proper_distance)^2 + 
              d_LOS_scaled_symmetric(vector1, vector2, redshift1, redshift2)^2
		)
}


#######################################
# Get a dist object made up from s_distances
# use a coordintates matrix as follows:
#	a<- mm[,c('x', 'y', 'z', 'dist', 'redshift')]
#   matriz_distancias <- get_matrix_of_distances(a)
# The aim is to call optics with this object as follows
#   aaa <- as.dist(matriz_distancias)
#   res <- optics(aaa, minPts = min_members)
#######################################
get_matrix_of_distances <- function(matrix_coordintates) {
	row_list <- as.list(data.frame(t(matrix_coordintates)))
	distances_matrix <- outer(row_list, row_list, FUN = Vectorize(s_distance))
	#as.dist(distances_matrix) This is not needed anymore
	distances_matrix
}
```

## sDistances Matrix Calculation

And then we can calculate distance matrix to apply OPTICS to this new metric, following code takes a lot of time:

```{r}
a<- mm[,c('x', 'y', 'z', 'dist', 'redshift')]
distance_matrix <- get_matrix_of_distances(a)
dist_object <- as.dist(distance_matrix)

```

## OPTICS

```{r}
sres <- optics(dist_object, minPts = min_members)
plot(sres)
```

## DBSCAN:

```{r}
sblo_scan <- extractDBSCAN(sres, eps_cl = 0.00025)
mm$cluster_id <- sblo_scan$cluster
mm5 <- update_mm5(mm)
plot(sblo_scan)
```

We obtain a notable improvement:

```{r}
sall <- execute_stats(mm, sblo_scan)
print(paste("Mean purity", mean(sall$purity)))
print(paste("Mean completness", mean(sall$completn)))
```

Test several hyper-parameters:

```{r}
#optimal value found at 0.00015
eps_sequence_test <- seq(0.00010, 0.00035, 0.00005)
sx_stats <- extract_stats(eps_sequence_test, sres)

```

```{r}
pretty_print(pretty_print("Completeness", sx_stats$completeness_list))
pretty_print(pretty_print("Purity", sx_stats$purity_list))
pretty_print(pretty_print("Groups", sx_stats$group_list))
pretty_print(pretty_print("Clusters", sx_stats$cluster_list))
pretty_print(pretty_print("EPS", eps_sequence_test))
pretty_print(paste("True Groups", true_groups))
pretty_print(pretty_print("Und. Groups", sx_stats$und_gr))
pretty_print(pretty_print("Complete gr.:", sx_stats$completes))
pretty_print(pretty_print("Pure gr.:", sx_stats$pures))
pretty_print(pretty_print("Fr:", sx_stats$fr_list))
pretty_print(pretty_print("Fp:", sx_stats$fp_list))
pretty_print(pretty_print("Spurious:", sx_stats$spurious))
pretty_print(pretty_print("Bad class:", sx_stats$bad_class))

```

```{r}

plot_purity_completeness_trend(
  eps_sequence_test, 
  sx_stats$purity_list, 
  sx_stats$completeness_list,
  c('Purity', 'Completeness'),
  'Purity Completeness on Slos data',
  0.000132, 'eps', 'Percentage'
)
```

There is a notable improvement of the results with the sLos distances.

Finally, for groups:

```{r}

plot_purity_completeness(
  eps_sequence_test, 
  sx_stats$pures/true_groups, 
  sx_stats$pure_complet/true_groups, 
  sx_stats$completes/true_groups,  
  c('Purity', 'Completeness', 'Pur.+Comp.'),
  "Purity and completeness on scaled data",
  0.000132, 'eps', 'Percentage'
  )

```

# Density Peaks Clustering(DPC )

Alex Rodriguez and Alessandro Laio (2014).

<https://github.com/thomasp85/densityClust>

By making this way it appears some clusters:

```{r}
if (!require('densityClust')) install.packages('densityClust')
library(densityClust)

galaxyDens <- densityClust(points)
galaxyClusters <- findClusters(galaxyDens, rho=0.99, delta=0.0026)
plot(galaxyClusters)
plotMDS(galaxyClusters)
galaxyClusters$cluster # The clusters dor dataset

mm$cluster_id <- galaxyClusters$cluster
mm5 <- update_mm5(mm)
```

## Other functions to asses globally (unused by now)

Following calculation is for global clusters, once we have outcomes dataset:

```{# {r}
# 
# ##############################################################################
# Get the purity rate: a cluster is said to be pure if 2/3 of his
# elements belong to a single cluster.
# ##############################################################################
# get_global_purity_rate <- function(outcomes_dataset, min_members = min_members) {
# 	current <- outcomes_dataset[outcomes_dataset$total_in_group >= min_members,]
# 	pures <- nrow(outcomes_dataset[outcomes_dataset$purity > 0.666,])
# 	pures / nrow(outcomes_dataset)
# }


###############################################################################
#	Get the completeness rate: a cluster is said to be complete if 1/2 of his
#	elements belong to a single cluster.
###############################################################################
# get_global_completeness_rate <- function(outcomes_dataset, min_members = min_members) {
# 	current <- outcomes_dataset[outcomes_dataset$total_in_group >= min_members,]
# 	completes <- nrow(outcomes_dataset[outcomes_dataset$completeness > 0.5,])
# 	completes / nrow(outcomes_dataset)
# }


###############################################################################
#	Get the recovery rate:  (pure+complete) / total_true_groups
###############################################################################
# get_global_recovery_rate <- function(outcomes_dataset, original_data_set, min_members = min_members) {
# 	total_true_groups <-sqldf(sprintf("
# 	    select 
# 	      how_many, 
# 	      group_id 
# 	    from (
# 						select
# 						  count(group_id) as how_many,
# 						  group_id 
# 						from 
# 						  original_data_set 
# 						group by 
# 						  group_id 
# 						order by how_many desc
# 						) a
# 	    where 
# 	         a.how_many>=%s 
#       order by 
# 	         how_many 
# 	   desc", min_members))
# 
# 	current <- outcomes_dataset[outcomes_dataset$total_in_group >= min_members,]
# 	pures_and_complete <- nrow(outcomes_dataset[outcomes_dataset$purity>0.6 & outcomes_dataset$completeness>0.5,])
# 	pures_and_complete / nrow(total_true_groups)
# }

```
