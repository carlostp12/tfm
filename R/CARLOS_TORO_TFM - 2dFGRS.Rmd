---
title: "TFM-Density algorithms applied to SDSS"
author: "Carlos Toro Pe√±as"
date: '2025-12-15'
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  word_document: default
  pdf_document:
    toc: yes
    number_sections: true
    df_print: kable
    highlight: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}

if (!require('jsonlite')) install.packages('jsonlite')
library(jsonlite)
if (!require('dbscan')) install.packages('dbscan')
library(dbscan)
if (!require('readr')) install.packages('readr')
library(readr)
if (!require('rjson')) install.packages('rjson')
library(rjson)

if (!require('dplyr')) install.packages('dplyr')
library(dplyr)

if (!require('akima')) install.packages('akima')
library(akima)

if (!require('astrolibR')) install.packages("astrolibR")
library(astrolibR)

if (!require('scatterplot3d')) install.packages("scatterplot3d")
library(scatterplot3d)

if (!require('gMOIP')) install.packages("gMOIP")
library(gMOIP)

if (!require('ggplot2')) install.packages("ggplot2")
library(ggplot2)

if (!require('rgl')) install.packages("rgl")
library(rgl)

if (!require('pracma')) install.packages("pracma")
library(pracma)

if (!require('plotly')) install.packages("plotly")

library(plotly)

if (!require('sqldf')) install.packages("sqldf")
library(sqldf)

if (!require('tidyr')) install.packages("tidyr")
library(tidyr)

if (!require('densityClust')) install.packages('densityClust')
library(densityClust)

if (!require('densityClust')) install.packages('densityClust')
library(densityClust)
```

# The clustering problem on galaxy dataset

We want, in this work apply some clustering algorithms, and the compare the obtained models with the halo-based group finder optimized for grouping galaxies that reside in the same dark matter halo.

In other words: this is not a normal clustering problem where we want to find a model where most of the samples belong to a group in an hypotetical method maximixed by the "Elbow method".

We want find some hyperparameters configuration makes possible to modelize the data-groups given by the halo-based finder.

# Loading data files

## Galaxy catalog for 2dFGRS

```{r echo=FALSE, message=FALSE, warning=FALSE}
######################
#     Galaxy 2dFGRS loading # 
######################
folder <- Sys.getenv('PROJECT_TFM')
folder <- sprintf('%s/data/2dfgrs/', folder)
file <- '2dfgrs-valid.csv'
setwd(folder)
dt <- read.csv(file)
str(dt)
```

# Data Preprocessing

## Descriptive analysis. **Data selection and visualization**

There is an initial preprocessing of data-file in order to obtain proper distances and cartesian coordinates x,y,z, by now it is omitted here.

Take a sample bounded by minPts = 5 and RA and DEC:

$$RA \in [0, 2],\, DEC \in [-29, -27],\, \,and\,\, z \lt max\_redshift$$

Then we take the initial values:

```{r}
SLOS <- 0 #Here the slos is not fixed beforehand
min_members <- 5
max_redshift <- 0.1
min_redshift <- 0.0
ra_lim_inf <-  0
ra_lim_sup <- 30
dec_lim_inf <- -36
dec_lim_sup <-  -25

# Take a sample using boundaries
mm <- dt[ dt$ra<= ra_lim_sup & dt$ra>=ra_lim_inf & 
            dt$dec>= dec_lim_inf & dt$dec<=dec_lim_sup &
            dt$redshift< max_redshift & dt$redshift> min_redshift,]


# mm is an object containing both groups and galaxy identification
ggplot(mm, aes(x=redshift, y=redshift))+geom_violin()
```

```{r}
dim(mm)
```

Select groups with more than min_members members queries:

```{r}
h<-sqldf("select 
            count(GAL_ID) as members, 
            GROUP_ID 
          from 
            mm 
          group by 
            GROUP_ID 
          order by  
            members desc")
mm5<-sqldf(sprintf("
    SELECT 
        mm.GAL_ID,
        mm.x, 
        mm.y, 
        mm.z, 
        mm.GROUP_ID, 
        mm.redshift, 
        mm.dist
      FROM 
        mm as mm, h 
      where 
          mm.GROUP_ID=h.GROUP_ID and 
          h.members >= %s"
      , min_members))

get_elements_in_m5_groups <- function(mm){
	groups_in_mm5<-sqldf(sprintf("
	      select
	          mm.GAL_ID,
	          mm.x, 
	          mm.y, 
	          mm.z, 
	          mm.GROUP_ID, 
	          mm.redshift, 
	          mm.dist,  
	          mm.cluster_id 
	      from 
	          mm as mm, h 
        where 
            mm.GROUP_ID=h.GROUP_ID and 
	          h.members >= %s", min_members))
	groups_in_mm5
}
```

Then use it to find the target data:

```{r}

true_groups <- length(unique(mm5$GROUP_ID))
number_non_isolated_galaxies <- dim(mm5)[1]
number_isolated_galaxies <- dim(mm)[1] - dim(mm5)[1]
print(sprintf('Number of galaxies in groups with 
              more than %s elements %s out of %s, aprox %s percent', 
          min_members, 
          number_non_isolated_galaxies, 
          dim(mm)[1], format(number_non_isolated_galaxies * 100
                                /dim(mm)[1], digits=4)))
print(sprintf("Number of groups with more than %s members: %s", 
              min_members, 
              true_groups))
```

We take a look at the groups with more than min_members:

```{r}
hhh<- h[h$members>=min_members, ]
ttable <- table(hhh$GROUP_ID, hhh$members)
barplot(ttable, col=('red'), 
        main=sprintf("Group distribution (%s) with at least %s members ", 
                     true_groups, 
                     min_members))
```

```{r}
boxplot(hhh$members, main="Boxplot of wt")
```

Lets take a look at the complete target sample:

```{r}
plot3d(mm$x, mm$y, mm$z, col = 'black', 
       size = 1, xlab = "X", ylab = "Y", zlab = "Z")
```

```{r}
aa <- sqldf("select 
	  	  GAL_ID,
	      x, 
	      y, 
	      z, 
		    case 
  			  when group_id IN (Select GROUP_ID from mm5) then group_id
	      else 0
		    end as group_id, 
	      redshift, 
	      dist
	  from 
		    mm")

plot3d(aa$x, aa$y, aa$z, col = aa$group_id+1, 
       size = 2, xlab = "X", ylab = "Y", zlab = "Z")
```

And the groups with more than min_members:

```{r}
plot3d(mm5$x, mm5$y, mm5$z, col = mm5$GROUP_ID, 
       size = 2, xlab = "X", ylab = "Y", zlab = "Z")
```

# Generic functions for assessments

## Functions to asses outcomes

To aseess the outcomes we will based our analysis on two basic concepts:

**Purity(P)**: measure of output-cluster: proportion of members coming exclusively from a single true group, providing confidence that the algorithm correctly groups members together. A high purity rate indicates the algorithm's effectiveness in identifying true groups.

**Completeness (C)**: measure of an output-cluster: proportion of data true-group elements included in an output-cluster. A cluster is considered "complete" if contains all points of the original true group.

For this study we consider an output-cluster to be pure if P\>=0.66 (at least 2/3 of elements of an output-cluster belong to a single group). An original cluster is complete if C\>=0.5 (at least half data belong to an original true group)

**total_in_group:** number of elements in a given group.

**total_in_cluster:** number of elements in a given output-cluster.

**total_in_cluster_group:** number of elements in a given output-cluster belonging to a majority-group.

**undetected_groups**: original groups not detected as majority-group in output-clusters

Following code is aimed to asses the outcomes obtained with from an given output-cluster:

```{r}

###############################################################################
#	Number of elements in a given output-cluster
###############################################################################
calculate_count_of_cluster <- function(cluster_id, dataset){
	ttotal<-sqldf(sprintf("
	    select 
	      count(GAL_ID) as how_many
			from 
			  dataset
			where 
	       cluster_id =%s", cluster_id))
}


###############################################################################
#	Number of elements in a given true-group
###############################################################################
calculate_count_of_group <- function(group_id, dataset){
	ttotal<-sqldf(sprintf("
	  select 
	    count(GAL_ID) as how_many
		from 
		  dataset
		where 
		  group_id=%s
		group by 
	    group_id", group_id)) 
    list('how_many' = ttotal$how_many)
}


###############################################################################
#	The most common true-group of a given output-cluster and count elements in the
#	intersection group and cluster.
###############################################################################
calculate_majority_group <- function(cluster_id, dataset){
	ttotal<-sqldf(sprintf("
	  select 
	    count(GAL_ID) as how_many,
			group_id as group_id
		from 
		  dataset
		where 
		  cluster_id=%s
		  
		group by 
			group_id
		order by 
		  how_many desc 
	    limit 1", cluster_id)) 
    list('group_id' = ttotal$group_id,
         'how_many' = ttotal$how_many)
}

###############################################################################
#	Purity and Completeness: 
#		1- (P) how many in an output-cluster coming from a true-group.
#		2- (C) how many in the majority true-group are present in output-cluster.
#	An output-cluster is said to be pure if P- >= 0.666 
#	An output-cluster is said to be complete if C >= 0.5 
###############################################################################
calculate_stats <- function(cluster_id, dataset) {
  #print(sprintf('Calculating stats for  clusterID %s', cluster_id))
  total<-calculate_majority_group(cluster_id, dataset)
  #Number of elements in the cluster_id that also belong
  #to majority group
  total_in_cluster_group <- total$how_many
  group_id <- total$group_id
  
  #Total number of elements in a group
  total_in_group <- calculate_count_of_group(group_id, dataset)
  total_in_group <- total_in_group$how_many
  
  #Total number of elements in a cluster
  total_in_cluster<-calculate_count_of_cluster(cluster_id, dataset)
  total_in_cluster <- total_in_cluster$how_many
  
  #Purity: all of group in cluster/total un cluster
  purity <- ifelse(total_in_cluster > 0, total_in_cluster_group/total_in_cluster, 0)
  #completeness: all of group in cluster/total un group
  completeness <- ifelse(total_in_group > 0, total_in_cluster_group/total_in_group, 0)	
  
  bad_classified <- total_in_group - total_in_cluster_group # belowing to group but classified outside
  spurious <- total_in_cluster - total_in_cluster_group # Outside of the group classified inside
  list('cluster_id' = cluster_id, 
		'group_id' = group_id , 
		'total_in_group' = total_in_group, 
		'total_in_cluster' = total_in_cluster, 
		'total_in_cluster_group' = total_in_cluster_group,
		'purity' = purity,
		'completeness' = completeness,
		'spurious' = spurious,
		'bad_classified' = bad_classified,
		'is_pure' = ifelse(purity>=0.666, 1, 0),
		'is_complete' = ifelse(completeness >= 0.5, 1, 0)
	   )
}


############################################################################
# Execute stats from a given mm dataset and a db_scan execution result
# delete column from dataframe: mm <- select(mm, -'cluster')
############################################################################
execute_stats <- function(mm, blo_scan){
  
	#mm0 <- mm[mm$cluster != 0, ]
	cluster_results <-sqldf("
    select 
	    distinct(cluster_id) AS cluster
		FROM 
	    mm")
	stats <- data.frame('cluster_id'=integer(),
		'group_id'=integer(),
		'total_in_group'=integer(),
		'total_in_cluster'=integer(),
		'total_in_cluster_group'=integer(),
		'purity'=numeric(),
		'completn'=numeric(),
		'spurious'=numeric(),
		'bad_class'=numeric(),
		'is_pur'=integer(),
		'is_comp'=integer(),
		'recovery'=numeric()
		)
	for(r in cluster_results$cluster){
	  if(r != 0) {
		bb <- calculate_stats(r, mm)
		stats[nrow(stats) +1,] <- 
			c(  bb$cluster_id, 
				bb$group_id, 
				bb$total_in_group, 
				bb$total_in_cluster, 
				bb$total_in_cluster_group, 
				bb$purity, 
				bb$completeness, 
				bb$spurious,
				bb$bad_classified,
				bb$is_pure,  
				bb$is_complete,
				ifelse(bb$is_pure & bb$is_complete,
				       bb$total_in_group/number_non_isolated_galaxies,
				       0 ))
		}
		#print(r)
	}
	return (stats)
}

undetected_groups <- function(dataset){
  groups_results <-sqldf("
    select 
        distinct(GROUP_ID)
    from 
        mm5
    where 
      group_id not in (
        select 
          distinct(group_id) as group_id
		    from
          dataset
        )")
   groups_results
}

print_stats <- function(all_data) {
  print(paste("Mean purity", mean(all_data$purity)))
  print(paste("Mean completness", mean(all_data$completn)))
  s<- undetected_groups(all_data)
  print(paste("Undetected groups", length(s$GROUP_ID), "out of", true_groups))
  print(paste("Detected real groups", (true_groups-length(s$GROUP_ID)), "out of", true_groups))
}
# Pretty print a vector preceded by a title
pretty_print <- function (title, avector= c()){
  paste(title, do.call(paste, c(as.list(avector), sep = " ")))
}

print_global_stats <- function(global_stats, sequence_values) {
  print ('############### DATA FOR eps values ############')
  pretty_print(pretty_print("EPS", eps_sequence_test))
  print ('#############################################')
  
  print ('')
  print ('')  
  print(pretty_print("Completeness", global_stats$completeness_list))
  print(pretty_print("Purity", global_stats$purity_list))
  print(pretty_print("Groups", global_stats$group_list))
  print(pretty_print("Clusters", global_stats$cluster_list))
  print(pretty_print("EPS", sequence_values))
  print(paste("True Groups", true_groups))
  print(pretty_print("Und. Groups", global_stats$und_gr))
  print(pretty_print("Complete gr.:", global_stats$completes))
  print(pretty_print("Pure gr.:", global_stats$pures))
  print(pretty_print("Fr:", global_stats$fr_list))
  print(pretty_print("Fp:", global_stats$fp_list))
  print(pretty_print("Spurious:", global_stats$spurious))
  print(pretty_print("Bad class:", global_stats$bad_class))
  print(pretty_print("Recovery:", global_stats$recovery))
}
```

Following code is intended to calculate stats

```{r}
get_initial_stats_frame <- function(){
  stats <- data.frame(
		'purity_list'=integer(),
		'completeness_list'=integer(),
		'cluster_list'=integer(),
		'group_list'=integer(),
		'pures'=integer(),
		'completes'=integer(),
		'pure_complet'=integer(),
		'fp_list'=numeric(),
		'fr_list'=numeric(),
		'und_gr'=numeric(),
		'spurious'=numeric(),
		'bad_class'=numeric(),
		'recovery'=numeric()
		)
  stats
}
calculate_output <- function(mm){
  predicted_groups <- length(unique(mm$cluster_id))
  all <- execute_stats(mm, blo_scan)
  number_pure_groups <- nrow(all[all$purity >= 0.666,])
  number_complete_groups <- nrow(all[all$completn>=0.5,])
  number_pure_complete_groups <- nrow(all[all$purity >= 0.666 & all$completn >= 0.5,])
  fp <- number_pure_groups/predicted_groups
  fr <- number_pure_complete_groups / true_groups
  s <- undetected_groups(all)
  c(mean(all$purity), 
    mean(all$completn), 
    length(unique(all$cluster_id)), 
    length(unique(all$group_id)), 
    number_pure_groups, 
    number_complete_groups, 
    number_pure_complete_groups, 
    fp, fr, 
    length(s$GROUP_ID), 
    mean(all$spurious), 
    mean(all$bad_class),
    sum(all$recovery)
  )
}


#Function to get clusters-stats from DBSCAN clustering
extract_stats_dbscan <- function (eps_sequence_values, local_res) {
	stats <- get_initial_stats_frame()
	for (eps_test in eps_sequence_values) {
	  print(sprintf("Extracting DBSCAN stats for epsI=%s", eps_test))
	  blo_scan <- extractDBSCAN(local_res, eps_test)
    mm$cluster_id <- blo_scan$cluster
    mm5 <- get_elements_in_m5_groups(mm)
    alli <- calculate_output(mm)
    
    stats[nrow(stats) +1,] <- 
		  c(alli[1], alli[2], alli[3], 
		    alli[4], alli[5], alli[6], 
		    alli[7],  alli[8], alli[9], 
		    alli[10], alli[11], alli[12], 
		    alli[13])
	}
	stats
}

#Function to get clusters-stats from OPTICS clustering
extract_stats_XI <- function (eps_sequence_values, local_res) {
  stats <- get_initial_stats_frame()
		
	for (eps_test in eps_sequence_values) {
	  print(sprintf("Extracting XI stats for XI=%s", eps_test))
	  blo_scan <- extractXi(local_res, eps_test)
    mm$cluster_id <- blo_scan$cluster
    #mm5 <- get_elements_in_m5_groups(mm)
    alli <- calculate_output(mm)
    
		stats[nrow(stats) +1,] <- 
		  c(alli[1], alli[2], alli[3], 
		    alli[4], alli[5], alli[6], 
		    alli[7],  alli[8],alli[9], 
		    alli[10], alli[11], alli[12], 
		    alli[13])
	}
	stats
}

#Function to get clusters-stats from HDBSCAN clustering
extract_stats_hdbscan <- function (eps_sequence_values, points) {
  stats <- get_initial_stats_frame()
		
	for (eps_test in eps_sequence_values) {
	  print(sprintf("Extracting HDBSCAN stats for EPS= %s", eps_test))
	  blo_scan <- hdbscan(points, 
	                      minPts = min_members, 
	                      cluster_selection_epsilon  = eps_test)
    mm$cluster_id <- blo_scan$cluster
    #mm5 <- get_elements_in_m5_groups(mm)
    alli <- calculate_output(mm)
    
		stats[nrow(stats) +1,] <- 
		  c(alli[1], alli[2], alli[3], 
		    alli[4], alli[5], alli[6], 
		    alli[7],  alli[8],alli[9], 
		    alli[10], alli[11], alli[12], 
		    alli[13])
	}
	stats
}

#Function to get clusters-stats from DPC clustering
# rho can go fixed to 0.992
extract_stats_hdbscan <- function (delta_sequence_values, galaxyDens,
                                   rho=0.992, delta=0.0012) {
  
  stats <- get_initial_stats_frame()
		
	for (delta_test in delta_sequence_values) {
	  print(sprintf("Extracting DPC stats for EPS= %s", delta_test))
	  galaxyClusters <- findClusters(galaxyClusters, rho, delta_test)
	  
	  mm$cluster_id <- galaxyClusters$cluster
    #mm5 <- get_elements_in_m5_groups(mm)
    alli <- calculate_output(mm)
    
		stats[nrow(stats) +1,] <- 
		  c(alli[1], alli[2], alli[3], 
		    alli[4], alli[5], alli[6], 
		    alli[7],  alli[8],alli[9], 
		    alli[10], alli[11], alli[12], 
		    alli[13])
	}
	stats
}
```

## Functions for plotting results

We generated some functions to help us visualize the results graphically:

```{r}
########################################################################
# 3D function plotting
########################################################################
plot3D_cluster <- function(objectClustering, setPoints){
  plot3d(setPoints$x, setPoints$y, setPoints$z, 
       col = objectClustering$cluster + 1, size = 2, 
       xlab = "X", ylab = "Y", zlab = "Z")
}

plot_purity_completeness <- function(
    eps_sequence, 
    purity_l, 
    completeness_l, 
    pures_com, 
    titles, 
    title = "",
    x=0,
    labelx = 'X', labely = 'Y'
    ){
    test_data <- data.frame('d1' = eps_sequence)	
    g<- ggplot(test_data, aes(eps_sequence)) +
        geom_line(aes(y = purity_l, colour = titles[1])) + 
        geom_line(aes(y = completeness_l, colour = titles[2]))+  
        geom_line(aes(y = pures_com, colour = titles[3]))+
    ggtitle(title) +
      labs(x = labelx, y = labely)
    
    if (x>0){  
     g+ geom_vline(xintercept = x, linetype="dotted",)
    }else{
      g
    }
}

plot_purity_completeness_trend <- function(
    eps_sequence, 
    purity_l, 
    completeness_l, 
    titles, 
    title = "",
    x = 0,
    labelx = 'X', labely = 'Y')
  {
    test_data <- data.frame('d1' = eps_sequence)	
    g <- ggplot(test_data, aes(eps_sequence)) +
        geom_line(aes(y = purity_l, colour = titles[1])) + 
        geom_line(aes(y = completeness_l, colour = titles[2]))+
    ggtitle(title) +
    labs(x = labelx, y = labely)
    if (x>0){  
      g + geom_vline(xintercept = x, linetype="dotted",)
    }else{
      g
    }
}

pplot_purity_completeness <- function(
    eps_sequence, 
    mi_lista, 
    titles, 
    title = "",
    x=0,
    labelx = 'X', labely = 'Y'
    ){
	limit <- length(mi_lista)
    test_data <- data.frame('d1' = eps_sequence)	
	col = c("red", "blue", "green", "gray")
    i <- 1
  cols <- list()
	plot(eps_sequence, mi_lista[1]$uno, type="l", xlab = labelx, ylab = labely, main=title, col=col[1])
	cols[1] <- "red"
	for(i in 2:limit) {
      lines (eps_sequence, as.numeric(mi_lista[i]$uno), type="l", 'col' = col[i])
	    cols[i] <- col[i]
		  i <- i+1
	}
	if(x != 0){
		abline(v=x, col="yellow")
	}
	legend("topright", legend = titles, lty = 1, col=as.character(cols))
}


ppplot_purity_completeness <- function(
    df,
    names, 
    title = "",
    x=0,
    labelx = 'X', labely = 'Y'
    ){
	limit <- length(names)
	df[, names]
	df$cat <- rep(names, each=2)
	col = list("red", "blue", "green", "gray", "orange")
  i <- 1
  g <- ggplot(df, aes(x=eps))
	
	for(i in 1:limit) {
      g <- g +geom_line(aes(y=!!sym(names(df)[i])), colour= col[[i]])
      #print(names(x_stats)[i])
		  i <- i+1
	}
  g <- g + scale_color_identity(name = '',
                       breaks = c('red', 'blue'),
                       labels = c("TempMax", "TempMin"),
                       guide = 'legend')
  
  g <- g+ ggtitle(title) + labs(x = labelx, y = labely)
  
	if(x != 0){
		 g <- g + geom_vline(xintercept = x, linetype="dotted",)
	}
	g
}
```

# Raw data processing

We will process the data without any kind of scale or normalization.

## OPTICS

Optics clustering:

```{r}
points<- mm[,c('x', 'y', 'z')]

#clustering
res <- optics(points, minPts = min_members)
plot(res)

```

In the previous plot we can see how OPTICS modeling valleys (clusters) and the peaks (cluster-separation).

Execute with $\xi=0.3$:

```{r}
optics <- extractXi(res, xi=0.15)
plot(optics)
```

### Output-clusters visualization

Take a plot of the clustering obtained:

```{r}
plot3D_cluster(optics, mm)
```

Stats with different values

```{r}
all <- execute_stats(mm, optics)
print_stats(all)
```

## DBSCAN

We can directly apply extractDBSCAN on the OPTICS model.

```{r}
blo_scan <- extractDBSCAN(res, eps_cl = 0.00075)
mm$cluster_id <- blo_scan$cluster
mm5 <- get_elements_in_m5_groups(mm)
plot(blo_scan)
```

### Output-clusters visualization

We have, on one hand all groups with more than min_members members (made up by a reduced amount of galaxies from catalog)

in the other hand the output-clusters from DBSCAN:

```{r}
plot3D_cluster(blo_scan, points)
```

```{r}
all <- execute_stats(mm, blo_scan)
head(all, 5)
print_stats(all)
```

We can now test over different values in order to obtain optimal eps_cl hyper-parameter:

```{r}
#It is easy to transform onto a function which admits a sequence and a res set.
eps_sequence_test <- seq(0.0004, 0.001, 0.0002)
x_stats <- extract_stats_dbscan(eps_sequence_test, res)
```

Show the results obtained:

```{r}
print_global_stats(x_stats, eps_sequence_test)

```

Lets get a plots for completeness and purity:

We have the optimal point at \$\\epsilon= 0.0006, \$ where recovery =50% and completeness= 81% purity=65.5%

```{r}
seleced_eps <- 0.0006
plot_purity_completeness(
  eps_sequence_test, 
  x_stats$purity_list, 
  x_stats$completeness_list, 
  x_stats$recovery,
  c('Purity', 'Completeness', 'Recovery'),
  "Purity/completeness on not scaled data",
  seleced_eps, 'eps', 'Percentage'
)
```

This chart shows that optimal point is around $0.00055$. Is at this value where completeness is maximum and purity is still high.

```{r}

plot_purity_completeness(
  eps_sequence_test, 
  x_stats$pures/true_groups, 
  x_stats$und_gr/true_groups, 
  x_stats$pure_complet/true_groups,
  c('Purity', 'Undetected gr.', 'Pure + Complet.'),
  "Group global group purity and undetected stats on not scaled data",
  seleced_eps , 'eps', 'Percentage'
)
```

According with previous chart, the optimal value is $\epsilon = 6.10^{4}$. Given that at this value is reach the maximum purity, purity+completeness and the number of undetected groups remains at minimum.

```{r}
plot_purity_completeness(
  eps_sequence_test, 
  x_stats$und_gr,
  x_stats$group_list, 
  true_groups - x_stats$und_gr,
  c('Undetected', 'Groups', 'Detected'),
  "Total purity and completeness on scaled data",
   seleced_eps , 'eps', 'Groups number'
)
```

Once again the optimal point is at $\epsilon = 6.10^{4}$.

# HDBSCAN data processing

As said from theory, HDBSCAN does not generate a great model because it ability to detect clusters in sparse areas. It cause detect noise as clusters.

```{r}
cl <- hdbscan(points, minPts = 5)
length(unique( cl$cluster))
```

## Output-clusters visualization

```{r}
plot3D_cluster(cl, mm)
```

HDBSCAN do not work pretty well because it detects cluster in sparser areas which gives as a result cluster detection on noise regions.

# Density Peaks Clustering(DPC )

Alex Rodriguez and Alessandro Laio (2014).

<https://github.com/thomasp85/densityClust>

By making this way it appears some clusters:

```{r}
galaxyDens <- densityClust(points)
galaxyClusters <- findClusters(galaxyDens, rho=0.995, delta=0.001)
plot(galaxyClusters)

# do not use this takes a lot!!:
#plotMDS(galaxyClusters)

mm$cluster_id <- galaxyClusters$cluster
mm5 <- get_elements_in_groups(mm)
```

```{r}
all <- execute_stats(mm, galaxyClusters)
print_stats(all)

```

DPC is analogous to HDBCAN: the model do not fit well for the same reason: detecting clusters in noise regions.

## Output-clusters visualization

```{r}
plot3D_cluster(galaxyClusters, mm)
```

It is true that lot of groups are detected but mixed within in clusters

# Normalized data processing

We will perform a scale of data:

```{r}
points_scaled <- scale(points)
ress <- optics(points_scaled, minPts = min_members)
#optimal value obtained
blo_scans <- extractDBSCAN(ress, eps_cl = 0.025)
mm$cluster_id <- blo_scans$cluster
mm5 <- get_elements_in_m5_groups(mm)
```

Again we can do the same for scaled data:

```{r}
eps_sequence_test <- seq(0.035, 0.06, 0.005)
x_stats <- extract_stats_dbscan(eps_sequence_test, ress)
```

```{r}
print_global_stats(x_stats, eps_sequence_test)
```

Results look quite better when all variables are scaled to a mean=0, sd=1. The optimal value of eps gives more than 76% for both purity and completeness.

The same plots before

```{r}
seleced_eps <- 0.0370
plot_purity_completeness(
    eps_sequence_test, 
    x_stats$purity_list,
    x_stats$completeness_list,
    x_stats$recovery, 
    c('Purity', 'Completeness', 'Recovery'),
    "Group purity and undetected stats on not scaled data",
    seleced_eps, 'eps', 'Percentage'
)

```

```{r}
plot_purity_completeness(
  eps_sequence_test, 
  x_stats$und_gr,
  x_stats$group_list, 
  true_groups - x_stats$und_gr,
  c('Undetected', 'Groups', 'Detected'),
  "Purity and completeness on scaled data",
   seleced_eps, 'eps', 'Groups number'
)
```

## Hyperparameter tunning

We have selected that minPts = min_members, which is a reasonable value for interpreting a group / clustering.

From the DBSCAN theory we can use the elbow on:

```{r}
kNNdistplot(x = points_scaled, k = min_members)
abline(h =seleced_eps, lty = 3) 
```

How reader can see, the "elbow theory" does not apply here, the reason for this is that we are not trying to optimize the clusters given by the algorithm, instead we are trying to detect groups of galaxies classified by the .

In addition are data belonging to actual clusters with more than min_members members, this reduced the space to 774 galaxies out of more than 5000.

We can infer that optimal value is content within the interval (0.0023, 0.0033).

## Undetected original groups

The element whose groups were not detected are:

```{r}
get_elements_not_in_groups <- function(mm5, dataset_all){
  groups_results <- sqldf("select 
	  	  mm5.GAL_ID,
	      mm5.x, 
	      mm5.y, 
	      mm5.z, 
	      mm5.GROUP_ID, 
	      mm5.redshift, 
	      mm5.dist,  
	      0 as cluster_id
	  from 
		    mm5, dataset_all
	  where 
		  mm5.GROUP_ID 
		not in (select 
		  			group_id 
			    from dataset_all) 
			      group by mm5.GAL_ID,
	          mm5.x, 
	          mm5.y, 
	          mm5.z, 
	          mm5.GROUP_ID, 
	          mm5.redshift, 
	          mm5.dist")
  groups_results
}

get_elements_in_groups <- function(dataset_mm, dataset_all){
	tt<-sqldf(sprintf("
	      select
	          d.GAL_ID,
	          d.x, 
	          d.y, 
	          d.z, 
	          d.GROUP_ID, 
	          d.redshift, 
	          d.dist,  
	          d.cluster_id 
	      from 
	          dataset_mm as d, dataset_all a 
        where 
            d.GROUP_ID=a.GROUP_ID and 
	          d.cluster_id>0"))
	tt
}

```

```{r}
blo_scans <- extractDBSCAN(ress, eps_cl = seleced_eps)
mm$cluster_id <- blo_scans$cluster

all <- execute_stats(mm, blo_scans)

undetected <- get_elements_not_in_groups(mm5, all)
detected <- get_elements_in_groups(mm, all)

print(sprintf('Undetected groups: %s', length(unique(undetected$GROUP_ID))))
print(sprintf('Detected groups: %s', length(unique(detected$GROUP_ID))))
```

*NOTE* FOR THIS WORK MM5 and MM has to be reseted

Plot detected clusters

```{r}
plot3d(detected$x, detected$y, detected$z, 
       col = detected$GROUP_ID +1, size = 2, 
       xlab = "X", ylab = "Y", zlab = "Z")
```

Plot undetected clusters

```{r}
plot3d(undetected$x, undetected$y, undetected$z, 
       col = undetected$GROUP_ID, size = 2, 
       xlab = "X", ylab = "Y", zlab = "Z")
```

# s-Distances (SLos application)

Following coder allow to calculate the sdistance: It consists in make a elongation along the line of sight

```{r}
#######################################
# Calculate angle between two points
#######################################
#nulos <- 0
calculate_angle <- function(v1, v2) {
	dot_product <- sum(v1 * v2)
	mod_v1 <- sqrt(sum(v1^2))
	mod_v2 <- sqrt(sum(v2^2))
	acos_angle <- dot_product / (mod_v1 * mod_v2)
	bool <- abs(acos_angle)  >1 | is.na(acos_angle)
	if(bool == TRUE) {
		0
	}else{
		acos(acos_angle)
	}
	
}


#######################################
# Calculate traverse distance from proper distance
# simple Angle X Distance
#######################################
traverse_distance <- function(v1, v2, distance) {
	calculate_angle(v1, v2) * distance
}


#######################################
# Calculate scaled distance symmetric way
#######################################
d_LOS_scaled_symmetric <- function(v1, v2, redshift1, redshift2) {
	(d_LOS(v1, v2, redshift1) + d_LOS(v2, v1, redshift2)) / 2
}


#######################################
# Calculate scaled distance between two given vectors
# sfactor is global constant, f.e sfactor=0.2
# This formulae comes from Hai-Xia-Ma:2025:
# https://arxiv.org/abs/2405.09855
#######################################
d_LOS <- function(v1, v2, redshift) {
  if (SLOS>0){
    sfactor <- SLOS
  }else{
    if(redshift< 0.01){
		  sfactor <- 0.6
	  } else if(redshift< 0.04){
  		sfactor <- 0.5
	  } else if(redshift< 0.06){
		  sfactor <- 0.4
	  } else if(redshift< 0.08){
		  sfactor <- 0.35
	  }else if(redshift< 0.1){
		  sfactor <- 0.3
	  }else if(redshift< 0.12){
		  sfactor <- 0.19
	  }else if(redshift< 0.15){
		  sfactor <- 0.08
	  }else if(redshift< 0.2){
		  sfactor <- 0.01
	  }else {
		  sfactor <- 0.2
	  }
  }
	sfactor * sum((v1-v2)*v1) / sqrt(sum(v1^2))
}


#######################################
# Calculate elongated distance
# depends on sfactor (a factor, for example sfactor=0.2) and proper_distance
# v1 = c(x, y, x, distance)
# sfactor must be a global variable
#######################################
s_distance <- function(v1, v2){
  vector1 <- v1[1:3]
	vector2 <- v2[1:3]
	proper_distance <- v1[4]
	#proper_distance <- (v1[4] + v2[4])/2
	redshift1 <- v1[5]
	redshift2 <- v2[5]
  
    sqrt (traverse_distance(vector1, vector2, proper_distance)^2 + 
          d_LOS_scaled_symmetric(vector1, vector2, redshift1, redshift2)^2
		)
}


#######################################
# Get a dist object made up from s_distances
# use a coordintates matrix as follows:
#	a<- mm[,c('x', 'y', 'z', 'dist', 'redshift')]
#   matriz_distancias <- get_matrix_of_distances(a)
# The aim is to call optics with this object as follows
#   aaa <- as.dist(matriz_distancias)
#   res <- optics(aaa, minPts = min_members)
#######################################
get_matrix_of_distances <- function(matrix_coordintates) {
	row_list <- as.list(data.frame(t(matrix_coordintates)))
	distances_matrix <- outer(row_list, row_list, FUN = Vectorize(s_distance))
	#as.dist(distances_matrix) This is not needed anymore
	distances_matrix
}
```

## sDistances Matrix Calculation

And then we can calculate distance matrix to apply OPTICS to this new metric, following code takes a lot of time:

```{r}
a<- mm[,c('x', 'y', 'z', 'dist', 'redshift')]
distance_matrix <- get_matrix_of_distances(a)
#Following code last a long time to execute
dist_object <- as.dist(distance_matrix)

```

## OPTICS

```{r}
sres <- optics(dist_object, minPts = min_members)
plot(sres)
```

## DBSCAN:

```{r}
sblo_scan <- extractDBSCAN(sres, eps_cl = 0.00025)
mm$cluster_id <- sblo_scan$cluster
#mm5 <- get_elements_in_groups(mm)
plot(sblo_scan)
```

We obtain a notable improvement:

```{r}
sall <- execute_stats(mm, sblo_scan)
print_stats(sall)
```

Test several hyper-parameters:

```{r}
#optimal value found at 0.00015
eps_sequence_test <- seq(0.000095, 0.00020, 0.00005)
sx_stats <- extract_stats_dbscan(eps_sequence_test, sres)

```

```{r}
print_global_stats(sx_stats, eps_sequence_test)
```

```{r}
seleced_eps <- 0.000108
plot_purity_completeness(
  eps_sequence_test, 
  sx_stats$purity_list, 
  sx_stats$completeness_list,
  sx_stats$recovery,
  c('Purity', 'Completeness', 'Recovery'),
  'Purity Completeness on Slos data',
  seleced_eps, 'eps', 'Percentage'
)
```

There is a notable improvement of the results with the sLos distances.

Finally, for groups:

```{r}

plot_purity_completeness(
  eps_sequence_test, 
  sx_stats$pures/true_groups, 
  sx_stats$pure_complet/true_groups, 
  sx_stats$completes/true_groups,  
  c('Purity', 'Completeness', 'Pur.+Comp.'),
  "Purity and completeness on scaled data",
  seleced_eps, 'eps', 'Percentage'
  )

```

```{r}
plot_purity_completeness(
  eps_sequence_test, 
  sx_stats$und_gr,
  sx_stats$group_list, 
  true_groups - sx_stats$und_gr,
  c('Undetected', 'Groups', 'Detected'),
  "Purity and completeness on scaled data",
   seleced_eps, 'eps', 'Groups number'
)

```

Undetected groups

```{r}
get_elements_not_in_groups <- function(mm5, dataset_all){
  groups_results <- sqldf("select 
	  	  mm5.GAL_ID,
	      mm5.x, 
	      mm5.y, 
	      mm5.z, 
	      mm5.GROUP_ID, 
	      mm5.redshift, 
	      mm5.dist,  
	      0 as cluster_id
	  from 
		    mm5, dataset_all
	  where 
		  mm5.GROUP_ID 
		not in (select 
		  			group_id 
			    from dataset_all) 
			      group by mm5.GAL_ID,
	          mm5.x, 
	          mm5.y, 
	          mm5.z, 
	          mm5.GROUP_ID, 
	          mm5.redshift, 
	          mm5.dist")
  groups_results
}

get_elements_in_groups <- function(dataset_mm, dataset_all){
	tt<-sqldf(sprintf("
	      select
	          d.GAL_ID,
	          d.x, 
	          d.y, 
	          d.z, 
	          d.GROUP_ID, 
	          d.redshift, 
	          d.dist,  
	          d.cluster_id 
	      from 
	          dataset_mm as d, dataset_all a 
        where 
            d.GROUP_ID=a.GROUP_ID and 
	          d.cluster_id>0"))
	tt
}
```

```{r}

sblo_scan <- extractDBSCAN(sres, eps_cl = seleced_eps)
mm$cluster_id <- sblo_scan$cluster

all <- execute_stats(mm, sblo_scan)

undetected <- get_elements_not_in_groups(mm5, all)
detected <- get_elements_in_groups(mm, all)

print(sprintf('Undetected groups: %s', length(unique(undetected$GROUP_ID))))
print(sprintf('Detected groups: %s', length(unique(detected$GROUP_ID))))
```

Pot of detected groups

```{r}
plot3d(detected$x, detected$y, detected$z, 
       col = detected$GROUP_ID +1, size = 2, 
       xlab = "X", ylab = "Y", zlab = "Z")
```

Plot of not detected groups

```{r}
plot3d(undetected$x, undetected$y, undetected$z, 
       col = undetected$GROUP_ID +1, size = 2, 
       xlab = "X", ylab = "Y", zlab = "Z")
```

## Other functions to asses globally (unused by now)

Following calculation is for global clusters, once we have outcomes dataset:

```{r}

# Assume a symmetric function f(x)
f <- function(x, y) x*y

# Create a vector of numbers
x <- 1:5

# Compute outer() with outer() function
outer_result <- outer(x, x, f)

# Create a symmetric matrix using the faster method
n <- length(x)
lower_tri_indices <- which(outer(1:n, 1:n, function(i, j) i >= j), arr.ind = TRUE)
lower_tri_values <- f(x[lower_tri_indices[,1]], x[lower_tri_indices[,2]])
symmetric_result <- matrix(0, n, n)
symmetric_result[lower_tri_indices] <- lower_tri_values
#symmetric_result <- symmetric_result + t(symmetric_result) - diag(diag(symmetric_result))

# Compare the two results
print(outer_result)
print(symmetric_result)


```

Seria

```{r}
# Assume a symmetric function f(x)
f <- function(x, y) x*y

# Create a vector of numbers
x <- 1:5

# Compute outer() with outer() function
outer_result <- outer(x, x, f)

# Create a symmetric matrix using the faster method
n <- length(x)
lower_tri_indices <- which(outer(1:n, 1:n, function(i, j) i >= j), arr.ind = TRUE)
lower_tri_values <- f(x[lower_tri_indices[,1]], x[lower_tri_indices[,2]])
symmetric_result <- matrix(0, n, n)
symmetric_result[lower_tri_indices] <- lower_tri_values
#symmetric_result <- symmetric_result + t(symmetric_result) - diag(diag(symmetric_result))
symmetric <- as.dist(symmetric_result)
# Compare the two results
print(outer_result)
print(symmetric)
```

# Summary and conclusions

The bests results obtained with each method:

+----------+-------------+----------+------------+
| Method   | Data Sample | Outcomes | Conclusion |
+==========+=============+==========+============+
| OPTICS   | Non-scaled  | P: 0.72  |            |
|          |             |          |            |
|          |             | C: 0.72  |            |
|          |             |          |            |
|          |             | R        |            |
+----------+-------------+----------+------------+
| DBSCAN   | Non-scaled  | P: 0.72  |            |
|          |             |          |            |
|          |             | C: 0.72  |            |
|          |             |          |            |
|          |             | R: 0.45  |            |
+----------+-------------+----------+------------+
| HDBSCAN  | Non-scaled  | P        |            |
|          |             |          |            |
|          |             | C        |            |
|          |             |          |            |
|          |             | R        |            |
+----------+-------------+----------+------------+
| DPC      | Non-scaled  | P        |            |
|          |             |          |            |
|          |             | C        |            |
|          |             |          |            |
|          |             | R        |            |
+----------+-------------+----------+------------+
| sOPTICS  | Scaled      |          |            |
+----------+-------------+----------+------------+
| OPTICS   | Scaled      |          |            |
+----------+-------------+----------+------------+
| DBSCAN   | Scaled      |          |            |
+----------+-------------+----------+------------+
| HDBSCAN  | Scaled      |          |            |
+----------+-------------+----------+------------+

# Executive summary
