\phantomsection
\pagestyle{fancy}

\chapter{Implementation}
\onehalfspacing
%\addcontentsline{toc}{chapter}{State_of_art}
%\section{Introduction}


\section{ETL and preprocessing datasets}

This section describes the Data Engineering Pipeline that converts the astronomical raw data into the machine learning-ready format you used for 2dFGRS analysis.

Our Python framework acts as a bridge between the raw observational catalog and the unsupervised learning models. By producing a sanitized CSV with pre-calculated, scaled Cartesian coordinates to operate with maximum efficiency and physical accuracy which data definition is shown in table \ref{table:data}.

All sources and code can be downloaded from \href{https://github.com/carlostp12/tfm}{this link in Github}.

The final objective of this pipeline is to associate individual galaxies with their respective Dark Matter Halos or larger structures. To achieve this, this study follows the next three basic steps to merge the algorithmic output with the physical catalog:

\begin{enumerate}
	\item Format the galaxy catalog to a CSV file.
	\item Format the group catalog to a CSV file.
	\item Merge galaxy and group catalog and transform coordinates and distances.
\end{enumerate}	

The synthesis results in a unified dataset formatted for computational efficiency. The header of this processed file, which contains the spatial and environmental metadata for each galaxy, is displayed in Figure \ref{fig:cat}.

Due to the varying structures of the survey catalogs, the data acquisition and preparation phase is divided into distinct modules to ensure inter-survey compatibility.

\subsection{2dF Galaxy Redshift Survey (2dFGRS)} \label{data:2d}

\begin{enumerate}
	\item \textit{2dfGRS.dat}: Which comprises 245,591 individual galaxy entries. To ensure high-fidelity measurements and minimize redshift uncertainty, a quality constraint of $Q \geq 3$ was applied, excluding objects with poorly determined spectral features or low signal-to-noise ratios.
	
	\item \textit{group\_members}: a supplementary group-membership file consisting of 104,913 galaxies.
\end{enumerate}	


\subsection{Sloan Digital Sky Survey (SDSS)}

Among the diverse datasets provided by the SDSS archive, the imodelC\_1 file was identified as the most suitable for this analysis.

\begin{enumerate}
	\item \textit{SDSS7}: Galaxy catalog of the survey.
	\item \textit{imodelC\_1} Comprises 245,591 entries for each galaxy. (Again a quality constraint of $Q \geq 3$ was applied.)
\end{enumerate}	
	
Our pipeline performs a multi-source integration of the raw data files, executing the necessary joins and quality filters to produce a unified CSV file optimized for clustering analysis. A representative sample of this finalized data product is provided in Figure \ref{fig:cat}, demonstrating the successful synthesis of spatial and environmental metadata.

\begin{table}[]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Field-Name} & \textbf{FDescription} & \textbf{Field-Type} \\
\hline
 GAL\_ID & ID of galaxy en each catalog & numerical \\ \hline
 ra & Right ascension coordinate  & decimal \\  \hline
 dec & Declination coordinate  & decimal    \\ \hline
 x & X cartesian coordinate & decimal    \\ \hline
 y & Y cartesian coordinate & decimal    \\ \hline
 z & Z cartesian coordinate & decimal    \\ \hline
 redshift & Redshift value & decimal \\ \hline
 dist & Raw distance value & decimal  \\ \hline
 GROUP\_ID & id-group galaxy belongs to & numerical \\ \hline
\end{tabular}
\caption{Datasheet metadata.}
\label{table:data}
\end{table}

\subsection{Real-Space Galaxy Catalogue}

Finally, the SDSS "Real-Space Galaxy Catalogue" was incorporated into the analysis. This dataset provides galaxy coordinates that have been specifically reconstructed to account for Redshift-Space Distortions (RSD), following the principles detailed in Section \ref{section:real} and Section \ref{section:slos}. By utilizing this catalog, we are able to benchmark our density-based clustering results against a distribution that more accurately reflects the physical, three-dimensional positions of galaxies in the local Universe.

	\begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth]{./figs/catalog.jpg}
	\caption{ Final format of the dataset }
	\label{fig:cat}
	\end{figure}
	


	
\section{Application of density-based algorithms to datasets} \label{sect:aplication}

A comparative evaluation of several density-based clustering frameworks was conducted to assess their capability in reconstructing the physical halo distribution. The algorithms were selected based on their distinct approaches to density reachability, hierarchical extraction, and noise handling.

Several algorithms were tested in order to obtain a model of density clustering both for non-scaled and scaled data to ensure that the density metrics are isotropic and not biased by the differing scales of the coordinate axes.

\begin{itemize}
    \item OPTICS: Utilized to generate a reachability plot, providing a visualization of the hierarchical density structure and identifying the spatial ordering of galaxies.
	
	\item OPTICSXi: An extension of OPTICS used to extract clusters in a hierarchical mode by identifying steep density gradients (the $\xi$ parameter), allowing for the detection of clusters with varying densities.
	
	\item DBSCAN: Implemented as a baseline density-based method to identify clusters as density-connected components based on a fixed global proximity threshold ($\epsilon$).
	
	\item HDBSCAN: A robust hierarchical implementation that constructs a spanning tree to find stable clusters across all possible density scales, making it highly effective for multi-scale cosmological distributions.
	
	\item DPC (Density Peaks Clustering): Employed to identify clusters based on the detection of local density maxima and their relative distance from other high-density peaks, which is physically analogous to identifying halo centers.
		
	\item sOPTICS and sDBSCAN: These variants account for line-of-sight positional uncertainties due to redshift space distortions with the modified distances as explained at \ref{section:slos}
\end{itemize} \label{sel:algorithms}


It is important to emphasize that this study departs from traditional unsupervised clustering objectives, such as minimizing intra-cluster variance via the Elbow Method. Rather, the distribution of dark matter halos is established as the physical ground truth. Consequently, many standard clustering algorithms —and their default hyperparameter configurations— may fail to yield results consistent with our model of virialized galaxy groups, as they are not intrinsically designed to account for the specific density profiles of dark matter halos.

The performance of each algorithm is evaluated based on its Recovery Rate of known halo members. Selection criteria prioritize models that maximize the completeness and purity of identified groups relative to the 2dFGRS/SDSS group catalogs.

Guided by the validation protocols established in \cite{Hai-Xia-Ma:2025}, we employ the following metrics to assess the topological and member-wise similarity between the density-based models ($C$) and the halo-based ground truth ($H$):

Definitions of following sets:
\begin{itemize}
	\item $C$: output-cluster.
	\item $H$: original true-group. 
	%\item $total\_in\_cluster_group$: number of elements from the orignal group present in an output-cluster.
\end{itemize}
	
\begin{equation} \label{eq:purity}
%	 Purity = \mathcal{P} = \frac{total\_in\_cluster\_group}{total\_in\_cluster}
 \mathcal{P} = \frac{|C \cap H|}{|C|}
\end{equation}.

Then Purity, $\mathcal{P}$ is the number of elements in an output-cluster that belongs to a true-group divided by the total elements in the output-cluster.

\begin{equation} \label{eq:completeness}
%	 Completeness = \mathcal{C} = \frac{total\_in\_cluster\_group}{total\_in\_group} 
\mathcal{C} = \frac{|C \cap H|}{|H|}
\end{equation}.

So Completeness, $\mathcal{C}$ is the elements in an output-cluster that belongs to a true-group divided by the total elements in the true-group.

Also, the undetected groups $\mathcal{U}$ is measured in the stats: the number of true-groups no detected as an output-cluster, or more formally:

\begin{equation} \label{eq:purity}
%	 Purity = \mathcal{P} = \frac{total\_in\_cluster\_group}{total\_in\_cluster}
 \mathcal{U} = |H-C|
\end{equation}.

Formally, purity ($\mathcal{P}$) is synonymous with Precision, representing the fraction of identified members that truly belong to the target halo. Similarly, completeness ($\mathcal{C}$) corresponds to Sensitivity or Recall, measuring the proportion of actual halo members that were successfully recovered by the algorithm.

Following the categorical framework of \cite{Hai-Xia-Ma:2025} we define the thresholds:

\begin{itemize}
	\item Purity Threshold ($\mathcal{P} \geq 2/3$): An output-cluster is defined as \textit{Pure} if at least 66.7\% of its constituent galaxies originate from the same parent dark matter halo. 
	
	\item Completeness Threshold ($\mathcal{C} \geq 1/2$): An output-cluster is defined as \textit{Complete} if it successfully captures at least 50\% of the galaxies belonging to the true physical halo (or original true-group). This ensures that the algorithm has recovered the core structure of the virialized group.
\end{itemize}

Recovery $\mathcal{R}$, it has also been defined as a global measure of precision. If $H_{i_1}, ..., H_{i_k}$, are the complete and pure groups and $H_{total}$ is the sum of elements of all original-groups:

\begin{equation} \label{eq:purity_rate}
	\mathcal{R} = \frac{1}{H_{total}} \sum_{j=1}^{k}|H_{i_{j}}|
\end{equation}.

With these concepts we evaluate the ratios, respectively \textit{Purity-rate}, $F_{p}$, \textit{Completeness-rate} $F_{c}$, and \textit{Recovery-rate} $F_{r}$ as:
  
\begin{equation} \label{eq:purity_rate}
	F_{p} = \frac{N_{pure}}{N_{clusters}}
\end{equation}.

\begin{equation} \label{eq:completeness_rate}
	F_{c} = \frac{N_{complete}}{N_{clusters}}
\end{equation}.

\begin{equation} \label{eq:completeness_pure_rate}
	F_{r} = \frac{N_{complete\,and\,pure}}{N_{original\_groups}}
\end{equation}.


%\begin{equation} \label{eq:pure_complete_rate}
%	Fr = \frac{total\_in\_group}{number\_non\_isolated\_galaxies}
%\end{equation}.

To conclude this section, the absolute number of detected groups $N_{det}$ against the number of successfully matched halos ($N_{match}$) is evaluated. It is critical to clarify that $N_{det}$ and $N_{match}$ are aggregate total terms; a single physical Halo-Group may be partitioned into several discrete output clusters by the algorithm. Consequently, the undetected groups $\mathcal{U}$ factor must be introduced to account for this fragmentation.

\section{The Two-point Correlation Function Implementation} \label{sect:2pcf}

Complementing the algorithmic clustering analysis, a statistical study of the Two-Point Correlation Function (2PCF), denoted as $\xi(r)$, was conducted. 

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=.85\linewidth]{./figs/poisson-sample.jpg}
  \caption{Synthetic sample.} 
  \label{fig:synthetic}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=.85\linewidth]{./figs/real-sample.jpg}
  \caption{Actual 2dFGRS sample.}
  \label{fig:actual}
\end{minipage}
\end{figure}

Utilizing a custom Python framework, a representative sample from the 2dFGRS catalog (Figure \ref{fig:actual}) was benchmarked against a synthetic Poisson distribution (Figure \ref{fig:synthetic}). The observational volume was defined by a specific spatial window: Redshift ($z$) within the range $[0, 0.28]$, Right Ascension ($RA$) between $0^h$ and $30^h$ and declination ($\delta$) between $-27^\circ$ and $-30^\circ$. To ensure the robustness of the spatial analysis, the random catalog was generated to strictly mirror these geometric constraints. The clustering signal was then quantified using four distinct estimators based on the normalized pair counts: Data-Data ($DD$), Random-Random ($RR$), and Data-Random ($DR$).

To compute the correlation function, the separation distance range $[0, 571.6]$ $h^{-1}\text{Mpc}$ was discretized into equally sized bins with a resolution of $\Delta r = 1$ $h^{-1}\text{Mp}$. For each discrete interval, the pair counts $DD$, $RR$, and $DR$ were calculated. The resulting frequency distribution of these pairs across the distance bins is illustrated in Figure \ref{fig:pairs}, which serves as the primary input for the four statistical estimators. To sum up:

\begin{itemize}
    \item \textbf{DD(r)}: The normalized number of galaxy pairs from the observed catalog (2dFGRS/SDSS) separated by a distance$\Delta r = 1$.
    \item \textbf{RR(r)}: The normalized number of pairs from the synthetic Poisson catalog separated by a distance $\Delta r = 1$. This represents the "null hypothesis" of a non-clustered universe.
    \item \textbf{DR(r)}: The normalized number of cross-pairs between the observed and synthetic catalogs, used to account for the complex geometry and edges of the survey volume.
\end{itemize}


	\begin{figure}[h]
	\centering
	\includegraphics[width=0.75\textwidth]{./figs/bins-dis2.jpg}
	\caption{Pairs distribution in bins.}
	\label{fig:pairs}
	\end{figure}

Following the definitions established in Section \ref{2pcf1}, the four statistical estimators were  applied to each separation bin. By computing the correlation signal across the full range of $r$, we obtained a comparative profile of the spatial clustering as measured by the estimator formulations.

One important point is the use of scipy.spatial.KDTree package, which allow to improve the time response and calculations by providing an index in a set of k-dimensional space. This indexing strategy was pivotal for the 2PCF pair-counting, reducing the computational complexity from quadratic to logarithmic scales. This ensured that our hyperparameter grid search remained performant even when processing 3D comoving coordinates across $571.6 h^{-1} Mp$ scales.


To conclude this section, all datasets utilized in this study and the accompanying source code are available for download at the following repository: \href{https://github.com/carlostp12/tfm}{this link in Github}.