\phantomsection
\pagestyle{fancy}

\chapter{Introduction}
\onehalfspacing
%\addcontentsline{toc}{chapter}{Introduction}
%\section{Introduction}
\section{Context and motivation}

When studying the universe at medium and large scales, we enter the world of galaxy mapping (or galaxy surveys), which are studies based on the use of telescopes dedicated to obtaining big censuses of galaxies. These studies have many objectives, one of which is to map huge areas of the universe. Examples of those surveys are Two-degree Field Galaxy Redshift Survey (hereafter 2dFGRS) and the Sloan Digital Sky Survey (hereafter SDSS), which data this work relies.

Most of previous work, as we will see in the \label{sec:state-of_art} make use of such surveys as well by getting datasets drawn from surveys databases, and then machine learing methods are applied. 

When one looks at the data provided by the surveys, one realizes that the galaxy distribution is far from random; instead, the galaxies are aggregated by gravity and shaped by dark matter into so-called groups, and into more numerous aggregations called galaxy clusters. Still at larger scales, it has been established that the structure of the universe is formed by a vast cosmic web primarily composed of dark matter \cite{Eniasto:2014}. The topology of this cosmic web consists of a network of filaments enclosing large voids \cite{Anatole:2024}. These filaments, composed mainly of dark matter halos, contain baryonic matter which includes galaxy clusters and intergalactic matter. The largest and most populated clusters and superclusters of galaxies reside within these dark matter filaments, predominantly at their intersection points, and thus form the largest structures of the visible universe.

Determining the structure of these groups/clusters is therefore crucial for understanding the distribution of matter in the universe. This is where clustering algorithms come into play. As will be discussed in section \label{sec:state-of_art}, the density-based algorithms are the most appropriate for this study.


\subsection{Personal motivation}

Given my background and strong interest in astrophysics and cosmology, upon entering the field of Data Science, it is easy to recognize the vast potential for applying the multiple Machine Learning (ML) techniques to these scientific domains. In particular, the study of the large-scale structure of the Universe is, without a doubt, one of the most fascinating topics in science today and where ML methods can find a vast number of applications.

%% FUTURE INCLUSION OF M33 Image galaxy of our Local Group
%\begin{figure}[h]
%\centering
%\includegraphics[width=0.5\textwidth]{./figs/M33_2.jpg}
%\caption{M33: A galaxy belonging to our local group.}
%\label{fig:sample_figure}
%\end{figure}


\section{Goals}

There are two list of goals we considered to address separatedly:

\subsection {Main goals}
\begin{itemize}
	\item Apply density-based algorithms to galaxy datasets adquired from 2dFGRS and the Sloan Digital Sky Survey SDSS, in order to obtain a validated model that can effectively approximate the observed structure of the universe.
	\item Determine which of the applied algorithms work better and its possible causes.
\end{itemize}


\subsection {Secondary goals}
\begin{itemize}
	\item Generate a visualization map of the data used in this study.
	\item Create validation methods to obtain a hyper-parameter tunning that optimizes the galaxy cluster detection.
\end{itemize}

% sustentability from now it will be leave out
% \input{2_sustentability.tex}

\subsection{Sustainability, diversity, and ethical/social challenges}

Cosmological findings fundamentally change our understanding of humanity's place in the universe. Discoveries related to dark matter, dark energy, or the vastness of the cosmos can have profound philosophical implications.

\begin{description}
    \item[Sustainability] The most direct social responsibility implication lies in the immense power required to process and store astronomical data. This work while purely theoretical, relies on an infrastructure that carries a heavy sustainability burden. That is why focus on computational efficiency directly translates into lower energy consumption, this is the most tangible sustainability implication in this project project.
	
    \item[Ethical behaviour and social responsibility] The major impact on this matter have to do with how resources are used. This work only uses shared datasets, the license for which was freely made available by the authors for download. Of course, all references to them and to other previous works must be properly recognized, as this project would never have been possible without them.
	
	Another matter to be considered is the author's commitment to communicate the outcomes clearly and accurately to the public.
	
    \item[Diversity, gender and human rights] Astronomy and cosmology, like many sciences, have historically struggled with issues of diversity and inclusion gender and human rights matters, the author thing that, in general, the more advancing in science the more better for the society to deal with these questions.
\end{description}

It is important to finish that this work uses powerful analytical methods from Machine Learning techniques, all tools could be adapted for surveillance, military intelligence, or other uses that might infringe on human rights or privacy. Scientists must be mindful of how their methods and code are shared.

\section{Approach and methodology}

We will apply the phases drawn from the data life cycle, which are as follows.

 - Collection: we will downloasd datasets drawn from surveys such as the SDSS and 2DFGRS to generate galaxy clustering models. These datasets are available at \cite{Blanton:2005}:

https://gax.sjtu.edu.cn/data/Group.html
 
 - Storage: we will keep donwnloaded data set in csv files.
 - Preprocessing: stage containinig the tasks of cleaning, filtering, sampling, and fusion.
 - Analysis stage: which contains model building througth application of the algorithms and validation of the outcomes.
 - Visualization: graphical view of the results.

The third point is the longest; in fact, it is an iterative process dedicated to improving the results obtained from the models. All models will consist of unsupervised algorithms, particularly density-based ones.

To evaluate the performance of these models, the following criteria will be followed:

\begin{itemize}
    \item {Detected Clusters}: Groups successfully classified as clusters (often referred to as True Positives at the group level).

	\item {Undetected Clusters}: Groups not found or not identified in the clusters set (equivalent to True Negatives at the group level).

	\item {Cluster Purity Ratio}: The proportion of members in a detected cluster that actually belong to the underlying group/structure.

	\item {Cluster Completeness Ratio}: The proportion of members of a true underlying group/structure that are successfully included within the detected cluster.

	\item {Misclassified Members}: Individual data points (galaxies) belonging to a true group but classified outside of detected cluster. (Often referred to as False Negatives at the individual member level).

	\item {External Data Classified as Members}: Individual data points (galaxies) not belonging to a true group but erroneously classified inside a detected cluster. (Often referred to as False Positives at the individual member level).
\end{itemize}

For this study, both programming languages Python and R will be used.

\section{Schedule}

A Gantt diagram in figure \ref{fig:stages_figure} shows the different stages of project development. Excluding the final project defense, the stages have been grouped on three blocks:

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{./figs/gantt_conogram.png}
\caption{Stages of the project.}
\label{fig:stages_figure}
\end{figure}

\begin{itemize}
	\item The Planning stage (shown in green) involves gathering resources and defining the project's objectives.
	\item The technical development stage (shown in red) includes design, data processing, method application and outcomes assessment.
	\item Research and writing stages (shown in blue).
\end{itemize}

An iterative and continuous review of the results is performed throughout the analysis process due to several causes: issues stemming from the algorithms, data processing, and the workflow itself. As a result, initial objectives be rearranged and redefined. This is why the aditional objetives stage is necessary.
